#@#Default configuration values crawler sub system

Version=1.0
#Base directory for crawler program
BaseBinDir = /root/crawler

#BaseDirectory for the download files
BaseFolder=/var/android/crawler
AppFolder=$BaseFolder/app
TempFolder=$BaseFolder/temp
SampleFolder=$BaseFolder/sample
PackageFolder=$BaseFolder/package
ExecptionFolder=$BaseFolder/execption
DaemonFolder=$BaseBinDir/Daemon

#DeploySite cn/us
DeploySite=us

#android request context
LoggingID=615c740f5b48819a
applist=/root/AndroidCrawler/applist
AuthSubToken=DQAAAKQAAAAIRwtq-NXj4J30Wxe1eRBEVxEJZRDNtOe9qAfHoOVQbghovoDLnjZynhbd5nF6ySCnrv3swSCHFbBtaIsWaniT10iYWT3px8Tk9xa-2Q-LFE7mZ3GxzhkliTUGYnyYsOn9vx3kXpF1HwWPpeFmk-nvfj1HR8hCpqz-6nMeGIuk9qnw7G6qDnSSlh7sDy0tFU6-cPd8qyML2fcYhzsW1rPdiOd3MWepozfZbVTWkVoeLg
SleepInterval=20
MaxConnectTimes=2
UserID=17558788718787595785
DeviceID=3694984833747069996
AppDownloadURL=http://android.clients.google.com/market/download/Download
MarketApiURL=http://android.clients.google.com/market/api/ApiRequest
AppEntityCount=20
ApkEntityCount=50
AppUpdateInterval=6# time unit is hour
AppDiscoveryInterval=12# time unit is hour

Local_Gateway=www.google.com
##202.101.172.35

CenterServer=Localhost
#CenterServer=10.228.57.90
ServerUsername=
#the max number of process to run the crawler
MaxProcessNum=8

##Crawl strategy :  deepth first(1) or width first(0),
crawledStragate  =   0 			

##if the crawl deepth is bigger than the downloadDeep ,it will discarded
crawledDeep=5

#Crawl outside the given site or not :inside domain(1) or outside the domain
crawledInsideDomain=0

##only the links in the iframe or script will be check , and download
IframeAndScript=1

#internal WhiteList
InternalWhiteList = Internal_whitelist.txt


#official List
Official_HostnameList=offical.txt

#Logging level 
LogFlag = 1
LogFolder=$BaseFolder/log

#the time for the browse to try the url.
URLRetries                 			= 4

#Time in seconds to wait for a server to respond
URLTimeout											=40


#the time interval (seconds) need to  deal with the url,if the url is visited with TimeIntervalToCheck seconds,
### the crawler would not visit it
TimeIntervalToCheck=7200

#the download will abort  if the speed is slower than SlowDownloadRate bytes per  second for 2 minute,
SlowDownloadRate=30

#the longer time for one webpage to be download
WebpageDownloadMaxTime							=120

#the longer time for one image to be download
ImageDownloadMaxTime							=300

#the longer time for one apk to be download
ApkDownloadMaxTime							= 600





#The longest time to be run ,if the time is set to -1,it will not stop 
URLCrowlingMaxTime						=18000

#the max file size to be download,(default:50M)

MaxFileSize=50000000




#Maximum  of a URL; longer will be silently discarded
crawledMaxPages = 5000

#while froceCrawling=1 the system  will not crawl the page  if the page have not changed since last crawling
forceCrawling =1
 



##the url which submit the sampel to the cross_scan
SubmitToScan_AfterCrawling=1
ScannerSubmitURL=http://172.16.11.10/crossscan/submit_request.php



#Identifies MySQL database name, user and host
MySQLHost = localhost
#MySQLHost =localhost
MySQLUser= root
MySQLPasswd= 
MySQLDb	 = AMMS 



#use the record of the web-search result 
SearchResult_Start=0
SearchResult_Count=50


 
